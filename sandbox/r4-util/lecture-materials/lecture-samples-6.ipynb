{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fresh-monkey",
   "metadata": {},
   "source": [
    "# データサイエンス(Python)勉強会用 2022/02/18 (金)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-safety",
   "metadata": {},
   "source": [
    "### FashionMNIST データセット\n",
    "<概要><br>\n",
    "10種類の画像が70000枚(トレーニングデータ60000枚、テストデータ10000枚)入ったデータセット。<br>\n",
    "(縦[28] x 横[28] x 色[3: 8bitグレースケール])<br>\n",
    "\n",
    "◆種類<br>\n",
    "ラベル「0」： T-shirt/top（Tシャツ／トップス）<br>\n",
    "ラベル「1」： Trouser（ズボン）<br>\n",
    "ラベル「2」： Pullover（プルオーバー、頭から被って着る服）<br>\n",
    "ラベル「3」： Dress（ドレス）<br>\n",
    "ラベル「4」： Coat（コート）<br>\n",
    "ラベル「5」： Sandal（サンダル）<br>\n",
    "ラベル「6」： Shirt（シャツ）<br>\n",
    "ラベル「7」： Sneaker（スニーカー）<br>\n",
    "ラベル「8」： Bag（バッグ）<br>\n",
    "ラベル「9」： Ankle boot（アンクルブーツ、かかとが隠れる丈のブーツ）<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-parade",
   "metadata": {},
   "source": [
    "### 使用するモジュールを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# 今回、tensorflowのv2は使用しない\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-letters",
   "metadata": {},
   "source": [
    "### MNIST, FashionMNIST データセットを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_x, mnist_y), (_, _) = mnist.load_data()\n",
    "(f_mnist_x, f_mnist_y), (_, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-georgia",
   "metadata": {},
   "source": [
    "### 補助関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1次元ベクトル化\n",
    "def tensor_to_vector(input):\n",
    "    shape = input.get_shape()[1:].as_list()\n",
    "    dim = np.prod(shape)\n",
    "    return tf.reshape(input, [-1, dim]), dim\n",
    "\n",
    "# leaky ReLU活性化関数\n",
    "def leaky_relu(input):\n",
    "    return tf.maximum(0.2*input, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-dining",
   "metadata": {},
   "source": [
    "### DCGANクラスの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGANクラスの定義\n",
    "class DCGAN():\n",
    "    def __init__(\n",
    "            self,\n",
    "            batch_size=100,\n",
    "            image_shape=[28,28,1],\n",
    "            dim_z=100,\n",
    "            dim_W1=1024,\n",
    "            dim_W2=128,\n",
    "            dim_W3=64,\n",
    "            dim_ch=1,\n",
    "            ):\n",
    "        # クラス内変数の初期化\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape\n",
    "        self.dim_z = dim_z\n",
    "        self.dim_W1 = dim_W1\n",
    "        self.dim_W2 = dim_W2\n",
    "        self.dim_W3 = dim_W3\n",
    "        self.dim_ch = dim_ch\n",
    "        # TensorFlow内学習係数の定義\n",
    "        ## Generator\n",
    "        self.g_W1 = tf.Variable(tf.random_normal([dim_z, dim_W1], stddev=0.02), name=\"g_W1\")\n",
    "        self.g_b1 = tf.Variable(tf.random_normal([dim_W1], stddev=0.02), name=\"g_b1\")\n",
    "        self.g_W2 = tf.Variable(tf.random_normal([dim_W1, dim_W2*7*7], stddev=0.02), name=\"g_W2\")\n",
    "        self.g_b2 = tf.Variable(tf.random_normal([dim_W2*7*7], stddev=0.02), name=\"g_b2\")\n",
    "        self.g_W3 = tf.Variable(tf.random_normal([5, 5, dim_W3, dim_W2], stddev=0.02), name=\"g_W3\")\n",
    "        self.g_b3 = tf.Variable(tf.random_normal([dim_W3], stddev=0.02), name=\"g_b3\")\n",
    "        self.g_W4 = tf.Variable(tf.random_normal([5, 5, dim_ch, dim_W3], stddev=0.02), name=\"g_W4\")\n",
    "        self.g_b4 = tf.Variable(tf.random_normal([dim_ch], stddev=0.02), name=\"g_b4\")\n",
    "        ## Discriminator\n",
    "        self.d_W1 = tf.Variable(tf.random_normal([5,5,dim_ch,dim_W3], stddev=0.02), name=\"d_W1\")\n",
    "        self.d_b1 = tf.Variable(tf.random_normal([dim_W3], stddev=0.02), name=\"d_b1\")\n",
    "        self.d_W2 = tf.Variable(tf.random_normal([5,5,dim_W3,dim_W2], stddev=0.02), name=\"d_W2\")\n",
    "        self.d_b2 = tf.Variable(tf.random_normal([dim_W2], stddev=0.02), name=\"d_b2\")\n",
    "        self.d_W3 = tf.Variable(tf.random_normal([dim_W2*7*7,dim_W1], stddev=0.02), name=\"d_W3\")\n",
    "        self.d_b3 = tf.Variable(tf.random_normal([dim_W1], stddev=0.02), name=\"d_b3\")\n",
    "        self.d_W4 = tf.Variable(tf.random_normal([dim_W1, 1], stddev=0.02), name=\"d_W4\")\n",
    "        self.d_b4 = tf.Variable(tf.random_normal([1], stddev=0.02), name=\"d_b4\")\n",
    "        \n",
    "    def build_model(self):\n",
    "        # プレースホルダーの用意\n",
    "        Z = tf.placeholder(tf.float32, [self.batch_size, self.dim_z])  # Generatorへの入力\n",
    "        # 画像の用意\n",
    "        img_real = tf.placeholder(tf.float32, [self.batch_size]+self.image_shape)  # Discriminatorへの入力\n",
    "        img_gen = self.generate(Z)\n",
    "        # 出力\n",
    "        raw_real = self.discriminate(img_real)\n",
    "        raw_gen = self.discriminate(img_gen)\n",
    "        # 確率\n",
    "        p_real = tf.nn.sigmoid(raw_real)\n",
    "        p_gen = tf.nn.sigmoid(raw_gen)\n",
    "        # コスト関数の定義\n",
    "        discrim_cost = tf.reduce_mean(\n",
    "            -tf.reduce_sum(tf.log(p_real) + \\\n",
    "                           tf.log(tf.ones(self.batch_size, tf.float32) - p_gen), axis=1))\n",
    "        gen_cost = tf.reduce_mean(-tf.reduce_sum(tf.log(p_gen), axis=1))\n",
    "        \n",
    "        return Z, img_real, discrim_cost, gen_cost, p_real, p_gen\n",
    "        \n",
    "    def generate(self, Z):\n",
    "        # 1層目\n",
    "        fc1 = tf.matmul(Z, self.g_W1) + self.g_b1\n",
    "        bm1, bv1 = tf.nn.moments(fc1, axes=[0])\n",
    "        bn1 = tf.nn.batch_normalization(fc1, bm1, bv1, None, None, 1e-5)\n",
    "        relu1 = tf.nn.relu(bn1)\n",
    "        # 2層目\n",
    "        fc2 = tf.matmul(relu1, self.g_W2) + self.g_b2\n",
    "        bm2, bv2 = tf.nn.moments(fc2, axes=[0])\n",
    "        bn2 = tf.nn.batch_normalization(fc2, bm2, bv2, None, None, 1e-5)\n",
    "        relu2 = tf.nn.relu(bn2)\n",
    "        # [batch, dim_W2*7*7] -> [batch, 7, 7, dim_W2]\n",
    "        y2 = tf.reshape(relu2, [self.batch_size, 7,7,self.dim_W2])\n",
    "        # 3層目\n",
    "        conv_t1 = tf.nn.conv2d_transpose(y2, self.g_W3, strides=[1,2,2,1],\n",
    "                                         output_shape=[self.batch_size, 14,14,self.dim_W3]) + self.g_b3\n",
    "        bm3,bv3 = tf.nn.moments(conv_t1, axes=[0, 1, 2])\n",
    "        bn3 = tf.nn.batch_normalization(conv_t1, bm3, bv3, None, None, 1e-5)\n",
    "        relu3 = tf.nn.relu(bn3)\n",
    "        # 4層目\n",
    "        conv_t2 = tf.nn.conv2d_transpose(relu3, self.g_W4, strides=[1,2,2,1],\n",
    "                                         output_shape=[self.batch_size, 28, 28, self.dim_ch]) + self.g_b4\n",
    "        img = tf.nn.sigmoid(conv_t2)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def discriminate(self, img):\n",
    "        # 1層目\n",
    "        conv1 = tf.nn.conv2d(img, self.d_W1, strides=[1,2,2,1], padding=\"SAME\") + self.d_b1\n",
    "        y1 = leaky_relu(conv1)\n",
    "        # 2層目\n",
    "        conv2 = tf.nn.conv2d(y1, self.d_W2, strides=[1,2,2,1], padding=\"SAME\") + self.d_b2\n",
    "        y2 = leaky_relu(conv2)\n",
    "        # 3層目\n",
    "        vec, _ = tensor_to_vector(y2)\n",
    "        fc1 = tf.matmul(vec, self.d_W3) + self.d_b3\n",
    "        y3 = leaky_relu(fc1)\n",
    "        # 4層目\n",
    "        fc2 = tf.matmul(y3, self.d_W4) + self.d_b4\n",
    "        #y4 = tf.nn.sigmoid(fc2)\n",
    "        \n",
    "        return fc2\n",
    "    \n",
    "    def generate_samples(self, batch_size):\n",
    "        # ここでは指定したbatch_sizeでサンプルを生成するため，self.batch_sizeは使わない\n",
    "        Z = tf.placeholder(tf.float32, [batch_size, self.dim_z])\n",
    "        # 1層目\n",
    "        fc1 = tf.matmul(Z, self.g_W1) + self.g_b1\n",
    "        bm1, bv1 = tf.nn.moments(fc1, axes=[0])\n",
    "        bn1 = tf.nn.batch_normalization(fc1, bm1, bv1, None, None, 1e-5)\n",
    "        relu1 = tf.nn.relu(bn1)\n",
    "        # 2層目\n",
    "        fc2 = tf.matmul(relu1, self.g_W2) + self.g_b2\n",
    "        bm2, bv2 = tf.nn.moments(fc2, axes=[0])\n",
    "        bn2 = tf.nn.batch_normalization(fc2, bm2, bv2, None, None, 1e-5)\n",
    "        relu2 = tf.nn.relu(bn2)\n",
    "        # [batch, dim_W2*7*7] -> [batch, 7, 7, dim_W2]\n",
    "        y2 = tf.reshape(relu2, [batch_size, 7,7,self.dim_W2])\n",
    "        # 3層目\n",
    "        conv_t1 = tf.nn.conv2d_transpose(y2, self.g_W3, strides=[1,2,2,1],\n",
    "                                         output_shape=[batch_size, 14,14,self.dim_W3]) + self.g_b3\n",
    "        bm3,bv3 = tf.nn.moments(conv_t1, axes=[0, 1, 2])\n",
    "        bn3 = tf.nn.batch_normalization(conv_t1, bm3, bv3, None, None, 1e-5)\n",
    "        relu3 = tf.nn.relu(bn3)\n",
    "        # 4層目\n",
    "        conv_t2 = tf.nn.conv2d_transpose(relu3, self.g_W4, strides=[1,2,2,1],\n",
    "                                         output_shape=[batch_size, 28, 28, self.dim_ch]) + self.g_b4\n",
    "        img = tf.nn.sigmoid(conv_t2)\n",
    "        return Z, img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-tuner",
   "metadata": {},
   "source": [
    "### モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan_model = DCGAN(batch_size=128, image_shape=[28,28,1])\n",
    "Z_tf, image_tf, d_cost_tf, g_cost_tf, p_real, p_gen = dcgan_model.build_model()\n",
    "Z_gen, image_gen = dcgan_model.generate_samples(batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-elements",
   "metadata": {},
   "source": [
    "### セッション開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-johnston",
   "metadata": {},
   "source": [
    "### tensorflow変数の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrim_vars = [x for x in tf.trainable_variables() if \"d_\" in x.name]\n",
    "gen_vars = [x for x in tf.trainable_variables() if \"g_\" in x.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-mount",
   "metadata": {},
   "source": [
    "### 最適化メソッドの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_d = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(d_cost_tf, var_list=discrim_vars)\n",
    "optimizer_g = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(g_cost_tf, var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-locator",
   "metadata": {},
   "source": [
    "### TensorFlow内のグローバル変数の初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-cheat",
   "metadata": {},
   "source": [
    "### 生成画像の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(images, num_itr, rows, cols):\n",
    "    # タイトル表示\n",
    "    plt.title(num_itr, color=\"red\")\n",
    "    for index, data in enumerate(images):\n",
    "        # 画像データはrows * colsの行列上に配置\n",
    "        plt.subplot(rows, cols, index + 1)\n",
    "        # 軸表示は無効\n",
    "        plt.axis(\"off\")\n",
    "        # データをグレースケール画像として表示\n",
    "        plt.imshow(data.reshape(28,28), cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-imaging",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "def train(train_imgs, n_epochs, batch_size):\n",
    "    itr = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        index = np.arange(len(train_imgs))\n",
    "        np.random.shuffle(index)\n",
    "        trX = train_imgs[index]\n",
    "        \n",
    "        # batch_size毎のfor\n",
    "        for start, end in zip(\n",
    "                range(0, len(trX), batch_size),\n",
    "                range(batch_size, len(trX), batch_size)):\n",
    "            # 画像は0-1に正規化\n",
    "            Xs = trX[start:end].reshape([-1, 28,28,1]) / 255.\n",
    "            Zs = np.random.uniform(-1,1, size=[batch_size, dcgan_model.dim_z]).astype(np.float32)\n",
    "            \n",
    "            if np.mod(itr, 2) != 0 :\n",
    "                # 偶数番目はGeneratorを学習\n",
    "                _, gen_loss_val = sess.run([optimizer_g, g_cost_tf], feed_dict={Z_tf:Zs})\n",
    "                discrim_loss_val, p_real_val, p_gen_val \\\n",
    "                        = sess.run([d_cost_tf, p_real, p_gen], feed_dict={Z_tf:Zs, image_tf:Xs})\n",
    "                #print(\"=========== updating G ==========\")\n",
    "                #print(\"iteration:\", itr)\n",
    "                #print(\"gen loss:\", gen_loss_val)\n",
    "                #print(\"discrim loss:\", discrim_loss_val)\n",
    "            else:\n",
    "                # 奇数番目はDiscriminatorを学習\n",
    "                _, discrim_loss_val = sess.run([optimizer_d, d_cost_tf],\n",
    "                                               feed_dict={Z_tf:Zs, image_tf:Xs})\n",
    "                gen_loss_val, p_real_val, p_gen_val = sess.run([g_cost_tf, p_real, p_gen], \n",
    "                                                               feed_dict={Z_tf:Zs, image_tf:Xs})\n",
    "                #print(\"=========== updating D ==========\")\n",
    "                #print(\"iteration:\", itr)\n",
    "                #print(\"gen loss:\", gen_loss_val)\n",
    "                #print(\"discrim loss:\", discrim_loss_val)\n",
    "                \n",
    "            \n",
    "            #print(\"Average P(real)=\", p_real_val.mean())\n",
    "            #print(\"Average P(gen)=\", p_gen_val.mean())\n",
    "            itr += 1\n",
    "        \n",
    "        # サンプルを表示\n",
    "        z = np.random.uniform(-1,1, size=[32, dcgan_model.dim_z]).astype(np.float32)\n",
    "        generated_samples = sess.run([image_gen], feed_dict={Z_gen:z})\n",
    "        #plt.imshow(generated_samples[0][0].reshape(28,28), cmap=\"gray\", interpolation=\"nearest\")\n",
    "        visualize(generated_samples[0], epoch, 4,8)\n",
    "        print(\"epoch = \", epoch)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-vinyl",
   "metadata": {},
   "source": [
    "### 学習パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 20\n",
    "batch_size = 128\n",
    "display_interval = 5\n",
    "tgt_num = 6\n",
    "f_tgt_num = 5\n",
    "\n",
    "tgt_pos = np.where(mnist_y == tgt_num, True, False)\n",
    "f_tgt_pos = np.where(f_mnist_y == f_tgt_num, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## メモ\n",
    "## ラベル「0」： T-shirt/top（Tシャツ／トップス）\n",
    "## ラベル「1」： Trouser（ズボン）\n",
    "## ラベル「2」： Pullover（プルオーバー、頭から被って着る服）\n",
    "## ラベル「3」： Dress（ドレス）\n",
    "## ラベル「4」： Coat（コート）\n",
    "## ラベル「5」： Sandal（サンダル）\n",
    "## ラベル「6」： Shirt（シャツ）\n",
    "## ラベル「7」： Sneaker（スニーカー）\n",
    "## ラベル「8」： Bag（バッグ）\n",
    "## ラベル「9」： Ankle boot（アンクルブーツ、かかとが隠れる丈のブーツ）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-faith",
   "metadata": {},
   "source": [
    "### 学習開始(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mnist_x, ep, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mnist_x[tgt_pos], ep, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-sigma",
   "metadata": {},
   "source": [
    "### 学習開始(FashionMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(f_mnist_x, ep, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(f_mnist_x[f_tgt_pos], ep, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
